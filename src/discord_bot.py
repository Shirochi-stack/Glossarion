#!/usr/bin/env python3
"""
Glossarion Discord Bot
Translate files via Discord using your existing Glossarion installation

PDF Formatting Integration:
- When processing PDF files, the bot automatically uses the pdf_extractor module
- The pdf_extractor.generate_css_from_pdf() function detects and extracts:
  * base_font_size: The median font size from the PDF body text
  * font_family: The most common font family (mapped to web-safe fonts)
  * text_align: The predominant text alignment (left, center, right, justify)
  * line_height_ratio: The calculated line spacing ratio
- These variables are automatically applied during PDF -> HTML conversion
- No manual configuration needed - styling is preserved from the original PDF
"""

import discord
from discord import app_commands
from discord.ext import commands
import os
import sys
import asyncio
import tempfile
import shutil
import json
from typing import Optional

# Add src directory to path
# In this repo layout, `discord_bot.py` typically lives inside the `src/` directory.
# Older deployments may have a nested `src/src` structure, so detect the correct one.
_base_dir = os.path.dirname(__file__)
_nested_src_dir = os.path.join(_base_dir, "src")

if os.path.isdir(_nested_src_dir) and os.path.exists(os.path.join(_nested_src_dir, "config.json")):
    src_dir = _nested_src_dir
else:
    src_dir = _base_dir

sys.path.insert(0, src_dir)

# Import Glossarion modules
try:
    # Core translation modules
    import TransateKRtoEN
    import extract_glossary_from_epub
    import extract_glossary_from_txt
    from model_options import get_model_options
    from api_key_encryption import decrypt_config
    
    # File processing modules
    import pdf_extractor
    import epub_converter
    import enhanced_text_extractor
    import txt_processor
    
    # Glossary management
    import GlossaryManager
    import glossary_compressor
    
    # Chapter and text processing
    import chapter_splitter
    import Chapter_Extractor
    import chapter_extraction_manager
    
    # API and client modules
    import unified_api_client
    try:
        import async_api_processor
    except ImportError:
        async_api_processor = None
    import multi_api_key_manager
    
    # Utility modules
    import history_manager
    try:
        import metadata_batch_translator
    except ImportError:
        metadata_batch_translator = None
    import google_free_translate
    
    # Duplicate detection
    import advanced_duplicate_detection
    import duplicate_detection_config
    
    # Image translation (may not be used in Discord but import for completeness)
    try:
        import image_translator
    except ImportError:
        image_translator = None
    try:
        import manga_translator
    except ImportError:
        manga_translator = None
    try:
        import manga_integration
    except ImportError:
        manga_integration = None
    
    # Don't import GUI modules - they require Qt/PySide6
    # (translator_gui, GlossaryManager_GUI, QA_Scanner_GUI, etc.)
    
    GLOSSARION_AVAILABLE = True
    glossary_main = extract_glossary_from_epub.main
except ImportError as e:
    GLOSSARION_AVAILABLE = False
    glossary_main = None
    print(f"âš ï¸ Glossarion modules not available: {e}")
    def decrypt_config(c):
        return c

# Config file
CONFIG_FILE = os.path.join(src_dir, "config.json")

# Bot setup
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="/", intents=intents)

# Global storage for translation state
translation_states = {}


def _ephemeral(interaction: discord.Interaction) -> bool:
    """Use ephemeral responses in guilds; in DMs, send normal messages."""
    return interaction.guild is not None


class LogView(discord.ui.View):
    """View with buttons to toggle log display and stop translation"""
    def __init__(self, user_id: int):
        super().__init__(timeout=None)  # No timeout for persistent view
        self.user_id = user_id
    
    @discord.ui.button(label="Show More Logs", style=discord.ButtonStyle.secondary, emoji="ðŸ”½", custom_id="toggle_logs")
    async def toggle_logs(self, interaction: discord.Interaction, button: discord.ui.Button):
        """Toggle between compact and full log view"""
        state = translation_states.get(self.user_id)
        if not state:
            await interaction.response.send_message("âŒ Translation session expired", ephemeral=_ephemeral(interaction))
            return
        
        try:
            # Toggle the state
            state['show_full'] = not state.get('show_full', False)
            
            # Update button label
            if state['show_full']:
                button.label = "Show Less"
                button.emoji = "ðŸ”¼"
            else:
                button.label = "Show More Logs"
                button.emoji = "ðŸ”½"
            
            # Get log text based on current state
            logs = state.get('logs', [])
            if state['show_full']:
                log_text = '\n'.join(logs)
                if len(log_text) > 3900:
                    log_text = "..." + log_text[-3900:]
            else:
                log_text = '\n'.join(logs[-10:])
                if len(log_text) > 800:
                    log_text = log_text[-800:]
            
            if not log_text:
                log_text = "No logs yet..."
            
            embed = discord.Embed(
                title="ðŸ“š Translation in Progress",
                description=f"**Status:** Processing... ({len(logs)} logs)\n\n```{log_text}```",
                color=discord.Color.blue()
            )
            
            await interaction.response.edit_message(embed=embed, view=self)
        except Exception as e:
            sys.stderr.write(f"[BUTTON ERROR] {e}\n")
            try:
                await interaction.response.send_message(f"âŒ Error: {e}", ephemeral=_ephemeral(interaction))
            except:
                pass
    
    @discord.ui.button(label="Stop Translation", style=discord.ButtonStyle.danger, emoji="â¹ï¸", custom_id="stop_translation")
    async def stop_translation(self, interaction: discord.Interaction, button: discord.ui.Button):
        """Stop the translation process"""
        state = translation_states.get(self.user_id)
        if not state:
            await interaction.response.send_message("âŒ Translation session expired", ephemeral=_ephemeral(interaction))
            return
        
        try:
            state['stop_requested'] = True
            button.disabled = True
            button.label = "Stopped"
            button.style = discord.ButtonStyle.secondary
            
            await interaction.response.edit_message(view=self)
            await interaction.followup.send("â¹ï¸ Translation stop requested...", ephemeral=_ephemeral(interaction))
        except Exception as e:
            sys.stderr.write(f"[BUTTON ERROR] {e}\n")
            try:
                await interaction.response.send_message(f"âŒ Error: {e}", ephemeral=_ephemeral(interaction))
            except:
                pass


def load_config():
    """Load Glossarion config (decrypted)"""
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
            return decrypt_config(config)
    except:
        return {}


@bot.event
async def on_ready():
    print(f"âœ… {bot.user} is online!")
    try:
        synced = await bot.tree.sync()
        print(f"âœ… Synced {len(synced)} command(s)")
    except Exception as e:
        print(f"âŒ Failed to sync commands: {e}")


async def model_autocomplete(interaction: discord.Interaction, current: str):
    """Autocomplete for model selection - shows popular models from model_options.py"""
    if GLOSSARION_AVAILABLE:
        try:
            all_models = get_model_options()
            # Filter models that match current input
            if current:
                matches = [m for m in all_models if current.lower() in m.lower()]
            else:
                # Show popular models first when no input
                popular = ['gpt-4', 'gpt-4-turbo', 'gpt-4o', 'claude-3-5-sonnet', 'claude-3-opus', 
                          'gemini-2.0-flash-exp', 'gemini-1.5-pro', 'deepseek-chat']
                matches = [m for m in popular if m in all_models] + all_models[:15]
            
            # Return up to 25 choices (Discord limit)
            return [app_commands.Choice(name=m, value=m) for m in matches[:25]]
        except:
            pass
    
    # Fallback choices if model_options unavailable
    return [
        app_commands.Choice(name="gpt-4", value="gpt-4"),
        app_commands.Choice(name="gpt-4-turbo", value="gpt-4-turbo"),
        app_commands.Choice(name="claude-3-5-sonnet", value="claude-3-5-sonnet"),
        app_commands.Choice(name="gemini-2.0-flash-exp", value="gemini-2.0-flash-exp"),
    ]


@bot.tree.command(name="translate", description="Translate EPUB, TXT, or PDF file")
@app_commands.describe(
    api_key="Your API key",
    model="AI model to use (or type custom model name)",
    file="EPUB, TXT, or PDF file to translate (optional if using url)",
    url="Google Drive or Dropbox link to file (optional if using file attachment)",
    custom_endpoint_url="Custom OpenAI-compatible base URL (auto-enables when set; omit to disable)",
    google_credentials_path="Path to Google Cloud credentials JSON (for Vertex AI models)",
    extraction_mode="Text extraction method (default: Enhanced/html2text)",
    temperature="Translation temperature 0.0-1.0 (default: 0.3)",
    batch_size="Paragraphs per batch (default: 10)",
    max_output_tokens="Max output tokens (default: 65536)",
    disable_smart_filter="Disable smart glossary filter (default: False)",
    duplicate_algorithm="Duplicate handling: auto/strict/balanced/aggressive/basic (default: balanced)",
    manual_glossary="Manual glossary file (.csv or .json) to upload and use instead of auto-generated",
    enable_auto_glossary="Enable automatic glossary generation (default: True)",
    request_merge_count="Chapters per request (set >=2 to enable request merging; <=1 disables; omit to disable)",
    split_the_merge="Split merged translation output back into separate files (default: True)",
    send_zip="Return output as a ZIP archive instead of individual file (default: False)",
    compression_factor="Compression factor (1.0-3.0; overrides auto-compression if set)",
    thinking="Enable/disable AI thinking capabilities (GPT/Gemini/DeepSeek) - Default: True",
    gemini_thinking_level="Gemini 3 thinking level (low/high) - Default: high",
    gemini_thinking_budget="Gemini thinking budget (-1=auto, 0=disabled) - Default: -1",
    or_thinking_tokens="OpenRouter thinking tokens - Default: 2000",
    gpt_effort="GPT-5/OpenAI thinking effort (none/low/medium/high/xhigh) - Default: medium",
    target_language="Target language"
)
@app_commands.choices(extraction_mode=[
    app_commands.Choice(name="Enhanced (html2text)", value="enhanced"),
    app_commands.Choice(name="Standard (BeautifulSoup)", value="standard"),
])
@app_commands.choices(gemini_thinking_level=[
    app_commands.Choice(name="High", value="high"),
    app_commands.Choice(name="Low", value="low"),
])
@app_commands.choices(gpt_effort=[
    app_commands.Choice(name="None", value="none"),
    app_commands.Choice(name="Low", value="low"),
    app_commands.Choice(name="Medium", value="medium"),
    app_commands.Choice(name="High", value="high"),
    app_commands.Choice(name="XHigh", value="xhigh"),
])
@app_commands.autocomplete(model=model_autocomplete)
async def translate(
    interaction: discord.Interaction,
    api_key: str,
    model: str,
    file: discord.Attachment = None,
    url: str = None,
    custom_endpoint_url: Optional[str] = None,
    google_credentials_path: str = None,
    extraction_mode: str = "enhanced",
    temperature: float = 0.3,
    batch_size: int = 10,
    max_output_tokens: int = 65536,
    disable_smart_filter: bool = False,
    duplicate_algorithm: str = "balanced",
    manual_glossary: discord.Attachment = None,
    enable_auto_glossary: bool = True,
    request_merge_count: Optional[int] = None,
    split_the_merge: bool = True,
    send_zip: bool = False,
    compression_factor: float = None,
    thinking: bool = True,
    gemini_thinking_level: str = "high",
    gemini_thinking_budget: int = -1,
    or_thinking_tokens: int = 2000,
    gpt_effort: str = "medium",
    target_language: str = "English"
):
    """Translate file using Glossarion"""
    
    if not GLOSSARION_AVAILABLE:
        await interaction.response.send_message(
            "âŒ Glossarion not available", 
            ephemeral=_ephemeral(interaction)
        )
        return
    
    # Validate input - must have either file or URL
    if not file and not url:
        await interaction.response.send_message(
            "âŒ Please provide either a file attachment or a URL", 
            ephemeral=_ephemeral(interaction)
        )
        return
    
    # Get filename and validate extension
    if file:
        filename = file.filename
    elif url:
        # Extract filename from URL or use default
        if 'drive.google.com' in url:
            filename = 'google_drive_file.epub'  # Will be updated after download
        elif 'dropbox.com' in url:
            filename = 'dropbox_file.epub'  # Will be updated after download
        else:
            # Try to get filename from URL path
            from urllib.parse import urlparse, unquote
            parsed = urlparse(url)
            filename = unquote(os.path.basename(parsed.path)) or 'downloaded_file.epub'
    
    # Validate file extension
    if not (filename.endswith('.epub') or filename.endswith('.txt') or filename.endswith('.pdf')):
        await interaction.response.send_message(
            "âŒ File must be EPUB, TXT, or PDF format", 
            ephemeral=_ephemeral(interaction)
        )
        return

    # Validate request merge count early (if explicitly provided)
    if request_merge_count is not None and request_merge_count < 0:
        await interaction.response.send_message(
            "âŒ request_merge_count must be >= 0",
            ephemeral=_ephemeral(interaction)
        )
        return

    # Validate custom endpoint URL early (if provided)
    if custom_endpoint_url is not None:
        custom_endpoint_url = custom_endpoint_url.strip()
        if custom_endpoint_url and not (custom_endpoint_url.startswith('http://') or custom_endpoint_url.startswith('https://')):
            await interaction.response.send_message(
                "âŒ custom_endpoint_url must start with http:// or https://",
                ephemeral=_ephemeral(interaction)
            )
            return
    
    # Initial response (ephemeral - only visible to user)
    embed = discord.Embed(
        title="ðŸ“š Translation Started",
        description=f"**File:** {filename}\n**Model:** {model}\n**Target:** {target_language}",
        color=discord.Color.blue()
    )
    await interaction.response.send_message(embed=embed, ephemeral=_ephemeral(interaction))
    message = await interaction.original_response()
    
    # Create temp directory
    temp_dir = tempfile.mkdtemp(prefix=f"discord_translate_{interaction.user.id}_")
    input_path = os.path.join(temp_dir, filename)
    
    try:
        # Download file from attachment or URL
        if file:
            await file.save(input_path)
        elif url:
            import aiohttp
            
            # Convert Google Drive/Dropbox share links to direct download links
            download_url = url
            if 'drive.google.com' in url:
                # Extract file ID from various Google Drive URL formats
                if '/file/d/' in url:
                    file_id = url.split('/file/d/')[1].split('/')[0]
                elif 'id=' in url:
                    file_id = url.split('id=')[1].split('&')[0]
                else:
                    await interaction.edit_original_response(embed=discord.Embed(
                        title="âŒ Invalid URL",
                        description="Could not parse Google Drive file ID from URL",
                        color=discord.Color.red()
                    ))
                    return
                download_url = f"https://drive.google.com/uc?export=download&id={file_id}"
            elif 'dropbox.com' in url:
                # Convert Dropbox share link to direct download
                download_url = url.replace('www.dropbox.com', 'dl.dropboxusercontent.com').replace('?dl=0', '').replace('?dl=1', '')
                if '?dl=' not in download_url:
                    download_url += '?dl=1'
            
            # Download the file
            async with aiohttp.ClientSession() as session:
                async with session.get(download_url) as response:
                    if response.status == 200:
                        with open(input_path, 'wb') as f:
                            f.write(await response.read())
                        
                        # Try to get actual filename from response headers
                        if 'content-disposition' in response.headers:
                            import re
                            content_disp = response.headers['content-disposition']
                            fname_match = re.findall('filename="(.+)"', content_disp)
                            if fname_match:
                                actual_filename = fname_match[0]
                                # Update filename if we got a better one
                                new_input_path = os.path.join(temp_dir, actual_filename)
                                os.rename(input_path, new_input_path)
                                input_path = new_input_path
                                filename = actual_filename
                    else:
                        await interaction.edit_original_response(embed=discord.Embed(
                            title="âŒ Download Failed",
                            description=f"Failed to download file from URL (HTTP {response.status})",
                            color=discord.Color.red()
                        ))
                        return
        
        # Load config
        config = load_config()
        
        # Get system prompt from config
        prompt_profiles = config.get('prompt_profiles', {})
        if 'Universal' in prompt_profiles:
            system_prompt = prompt_profiles['Universal'].replace('{target_lang}', target_language)
        else:
            # Fallback to first available profile or basic prompt
            system_prompt = f"Translate to {target_language}. Preserve all formatting."
        
        # Custom OpenAI Endpoint (single source of truth: custom_endpoint_url)
        # If omitted, keep disabled.
        if custom_endpoint_url:
            os.environ['USE_CUSTOM_OPENAI_ENDPOINT'] = '1'
            os.environ['OPENAI_CUSTOM_BASE_URL'] = custom_endpoint_url
            sys.stderr.write(f"[CONFIG] Custom OpenAI Endpoint enabled: {custom_endpoint_url}\n")
        else:
            os.environ['USE_CUSTOM_OPENAI_ENDPOINT'] = '0'
            os.environ['OPENAI_CUSTOM_BASE_URL'] = ''
        
        # Set model and API key
        os.environ['MODEL'] = model
        os.environ['SYSTEM_PROMPT'] = system_prompt
        os.environ['OUTPUT_DIRECTORY'] = temp_dir
        
        # Set translation parameters
        os.environ['BATCH_TRANSLATION'] = '1'
        os.environ['BATCH_SIZE'] = str(batch_size)
        os.environ['MAX_OUTPUT_TOKENS'] = str(max_output_tokens)
        os.environ['TRANSLATION_TEMPERATURE'] = str(temperature)
        
        # Handle compression factor
        # If user provides a specific factor, disable auto-compression and use the value
        # If None (default), use the config/env default which typically enables auto-compression
        if compression_factor is not None:
            os.environ['COMPRESSION_FACTOR'] = str(compression_factor)
            os.environ['AUTO_COMPRESSION_FACTOR'] = '0'
            sys.stderr.write(f"[CONFIG] Manual compression factor: {compression_factor} (Auto-compression disabled)\n")
        else:
            # Respect config setting for auto-compression (default True)
            auto_comp = config.get('auto_compression_factor', True)
            os.environ['AUTO_COMPRESSION_FACTOR'] = '1' if auto_comp else '0'
            # Default compression factor if not auto (e.g. 1.0)
            if not auto_comp:
                os.environ['COMPRESSION_FACTOR'] = str(config.get('compression_factor', 1.0))
        
        # Disable contextual translation by default (each batch is independent)
        os.environ['CONTEXTUAL'] = '0'
        # Disable emergency paragraph restoration
        os.environ['EMERGENCY_PARAGRAPH_RESTORE'] = '0'
        # Enable AI artifact removal
        os.environ['REMOVE_AI_ARTIFACTS'] = '1'
        # Retain original source filenames (no 'response_' prefix)
        os.environ['RETAIN_SOURCE_EXTENSION'] = '1'
        
        # Disable input token limit by default (no chapter size restrictions)
        os.environ['TOKEN_LIMIT_DISABLED'] = '1'
        os.environ['DISABLE_INPUT_TOKEN_LIMIT'] = '1'
        os.environ['MAX_INPUT_TOKENS'] = ''  # Empty string = unlimited (matches GUI behavior)
        
        # Disable image translation for Discord bot (images don't work well via Discord)
        os.environ['ENABLE_IMAGE_TRANSLATION'] = '0'
        
        # Set extraction mode
        os.environ['TEXT_EXTRACTION_METHOD'] = extraction_mode
        if extraction_mode == 'enhanced':
            os.environ['EXTRACTION_MODE'] = 'enhanced'
            os.environ['ENHANCED_FILTERING'] = 'smart'
            os.environ['ENHANCED_PRESERVE_STRUCTURE'] = '1'
        else:
            os.environ['EXTRACTION_MODE'] = 'smart'
            os.environ['FILE_FILTERING_LEVEL'] = 'smart'
        
        # Set PDF-specific styling extraction variables from pdf_extractor
        # These ensure PDF font sizes, alignments, and styles are preserved
        if filename.endswith('.pdf'):
            sys.stderr.write(f"[CONFIG] Enabling PDF formatting extraction (font size, alignment, etc.)\n")
            sys.stderr.flush()
            # Force XHTML render mode for better PDF extraction quality
            os.environ['PDF_RENDER_MODE'] = 'xhtml'
            sys.stderr.write(f"[CONFIG] Using XHTML render mode for PDF\n")
            sys.stderr.flush()
            # The pdf_extractor.generate_css_from_pdf() function will automatically
            # detect and apply: base_font_size, font_family, text_align, line_height_ratio
            # from the actual PDF file during processing
        
        # Enable automatic glossary generation (user configurable)
        os.environ['ENABLE_AUTO_GLOSSARY'] = '1' if enable_auto_glossary else '0'
        # Set glossary parameters (use config if available, otherwise use defaults)
        os.environ['GLOSSARY_MIN_FREQUENCY'] = str(config.get('glossary_min_frequency', 2))
        os.environ['GLOSSARY_MAX_NAMES'] = str(config.get('glossary_max_names', 50))
        os.environ['GLOSSARY_MAX_TITLES'] = str(config.get('glossary_max_titles', 30))
        os.environ['APPEND_GLOSSARY'] = '1'
        os.environ['APPEND_GLOSSARY_PROMPT'] = config.get('append_glossary_prompt', '- Follow this reference glossary for consistent translation (Do not output any raw entries):\n')
        # CRITICAL: Auto glossary uses AUTO_GLOSSARY_PROMPT (unified prompt used by the GUI).
        # If this is missing, GlossaryManager falls back to the legacy honorific/title regex scanner.
        os.environ['AUTO_GLOSSARY_PROMPT'] = (
            config.get('unified_auto_glossary_prompt', '')
            or config.get('auto_glossary_prompt', '')
            or ''
        )
        # Ensure glossary translations target the same language as the main translation
        os.environ['GLOSSARY_TARGET_LANGUAGE'] = target_language
        os.environ['OUTPUT_LANGUAGE'] = target_language
        # Align throttling/timeouts with config defaults (matches GUI behavior)
        os.environ['SEND_INTERVAL_SECONDS'] = str(config.get('delay', 2.0))
        os.environ['THREAD_SUBMISSION_DELAY_SECONDS'] = str(config.get('thread_submission_delay', 0.5))
        os.environ['RETRY_TIMEOUT'] = '1' if config.get('retry_timeout', False) else '0'
        os.environ['CHUNK_TIMEOUT'] = str(config.get('chunk_timeout', 900))
        os.environ['ENABLE_HTTP_TUNING'] = '1' if config.get('enable_http_tuning', False) else '0'
        os.environ['CONNECT_TIMEOUT'] = str(config.get('connect_timeout', 10))
        # Don't set READ_TIMEOUT for the bot; chunk timeout is the single source of truth.
        os.environ.pop('READ_TIMEOUT', None)
        os.environ['HTTP_POOL_CONNECTIONS'] = str(config.get('http_pool_connections', 20))
        os.environ['HTTP_POOL_MAXSIZE'] = str(config.get('http_pool_maxsize', 50))
        os.environ['IGNORE_RETRY_AFTER'] = '1' if config.get('ignore_retry_after', False) else '0'
        # Cap retries for the Discord bot to keep runs predictable.
        os.environ['MAX_RETRIES'] = '3'
        # Set all glossary variables from GUI
        os.environ['GLOSSARY_COMPRESSION_FACTOR'] = str(config.get('glossary_compression_factor', 1.0))
        # Enable glossary prompt compression (filtering unused entries) by default
        os.environ['COMPRESS_GLOSSARY_PROMPT'] = '1' if config.get('compress_glossary_prompt', True) else '0'
        os.environ['GLOSSARY_FILTER_MODE'] = config.get('glossary_filter_mode', 'all')
        os.environ['GLOSSARY_STRIP_HONORIFICS'] = '1' if config.get('glossary_strip_honorifics', True) else '0'
        os.environ['GLOSSARY_FUZZY_THRESHOLD'] = str(config.get('glossary_fuzzy_threshold', 0.90))
        os.environ['GLOSSARY_MAX_TEXT_SIZE'] = str(config.get('glossary_max_text_size', 50000))
        # Cap glossary max sentences for the Discord bot to keep prompts small/predictable.
        # (GlossaryManager reads this via GLOSSARY_MAX_SENTENCES)
        os.environ['GLOSSARY_MAX_SENTENCES'] = '200'
        os.environ['GLOSSARY_CHAPTER_SPLIT_THRESHOLD'] = str(config.get('glossary_chapter_split_threshold', 50000))
        os.environ['GLOSSARY_SKIP_FREQUENCY_CHECK'] = '0'  # Enable frequency checking
        os.environ['CONTEXT_WINDOW_SIZE'] = str(config.get('glossary_context_window', 2))
        os.environ['GLOSSARY_USE_LEGACY_CSV'] = '0'  # Use modern JSON format
        os.environ['GLOSSARY_DUPLICATE_KEY_MODE'] = config.get('glossary_duplicate_key_mode', 'auto')
        os.environ['GLOSSARY_DUPLICATE_CUSTOM_FIELD'] = config.get('glossary_duplicate_custom_field', '')
        os.environ['GLOSSARY_DUPLICATE_ALGORITHM'] = duplicate_algorithm
        # Gender context and description for automatic glossary (enabled by default)
        os.environ['GLOSSARY_INCLUDE_GENDER_CONTEXT'] = '1' if config.get('include_gender_context', True) else '0'
        os.environ['GLOSSARY_INCLUDE_DESCRIPTION'] = '1' if config.get('include_description', True) else '0'
        # Custom glossary fields (additional columns) - default to ['description']
        custom_fields = config.get('custom_glossary_fields', [])
        if not custom_fields and not config.get('custom_field_description_removed', False):
            custom_fields = ['description']
        os.environ['GLOSSARY_CUSTOM_FIELDS'] = json.dumps(custom_fields)
        # Glossary-specific overrides for API settings
        os.environ['GLOSSARY_MAX_OUTPUT_TOKENS'] = str(config.get('glossary_max_output_tokens', max_output_tokens))
        os.environ['GLOSSARY_TEMPERATURE'] = str(config.get('manual_glossary_temperature', 0.1))
        os.environ['GLOSSARY_REQUEST_MERGING_ENABLED'] = '0'  # Disable by default
        os.environ['GLOSSARY_REQUEST_MERGE_COUNT'] = str(config.get('glossary_request_merge_count', 10))
        
        # Set duplicate detection mode to balanced
        os.environ['DUPLICATE_DETECTION_MODE'] = 'balanced'
        
        # Disable batch translate headers (metadata translation)
        os.environ['BATCH_TRANSLATE_HEADERS'] = '0'
        
        # Set manual glossary path if provided (download attachment first)
        if manual_glossary:
            # Validate glossary file extension
            if manual_glossary.filename.endswith('.csv') or manual_glossary.filename.endswith('.json'):
                glossary_path = os.path.join(temp_dir, manual_glossary.filename)
                await manual_glossary.save(glossary_path)
                os.environ['MANUAL_GLOSSARY'] = glossary_path
                sys.stderr.write(f"[CONFIG] Using manual glossary: {manual_glossary.filename}\n")
                sys.stderr.flush()
            else:
                sys.stderr.write(f"[WARNING] Manual glossary must be .csv or .json: {manual_glossary.filename}\n")
                sys.stderr.flush()
        
        # Request merging settings (combine multiple chapters into single API request)
        # Single source of truth: request_merge_count
        if request_merge_count is None:
            # If omitted, keep merging disabled
            request_merging_enabled = False
            request_merge_count_raw = 1
        else:
            request_merge_count_raw = int(request_merge_count)
            request_merging_enabled = request_merge_count_raw >= 2

        # Keep the count safe for downstream code (even when disabled)
        request_merge_count_effective = max(1, request_merge_count_raw)

        os.environ['REQUEST_MERGING_ENABLED'] = '1' if request_merging_enabled else '0'
        os.environ['REQUEST_MERGE_COUNT'] = str(request_merge_count_effective)
        os.environ['SPLIT_THE_MERGE'] = '1' if split_the_merge else '0'
        os.environ['DISABLE_MERGE_FALLBACK'] = '1'  # Mark as qa_failed if split fails
        os.environ['SYNTHETIC_MERGE_HEADERS'] = '1'  # Use synthetic headers for better splitting
        
        # Disable Gemini safety filter by default (enabled for Discord bot)
        os.environ['DISABLE_GEMINI_SAFETY'] = 'true'
        
        # Handle Thinking Toggle
        # If thinking is True (default), we don't need to do anything as we respect the config/env
        # If thinking is False, we explicitly disable all thinking features
        if not thinking:
            os.environ['ENABLE_GPT_THINKING'] = '0'
            os.environ['ENABLE_GEMINI_THINKING'] = '0'
            os.environ['ENABLE_DEEPSEEK_THINKING'] = '0'
            sys.stderr.write(f"[CONFIG] Thinking capabilities disabled via command\n")
        
        # Handle Vertex AI / Google Cloud credentials
        if '@' in model or model.startswith('vertex/'):
            # Use provided credentials path, fallback to config if not provided
            google_creds = google_credentials_path if google_credentials_path else config.get('google_cloud_credentials')
            if google_creds and os.path.exists(google_creds):
                os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = google_creds
                sys.stderr.write(f"[CONFIG] Using Google Cloud credentials: {os.path.basename(google_creds)}\n")
                sys.stderr.flush()
                
                # Extract project ID from credentials
                try:
                    with open(google_creds, 'r') as f:
                        creds_data = json.load(f)
                        project_id = creds_data.get('project_id', 'vertex-ai-project')
                        os.environ['GOOGLE_CLOUD_PROJECT'] = project_id
                        if not api_key:
                            api_key = project_id
                except:
                    pass
        
        # Set API key - TransateKRtoEN checks multiple env vars
        os.environ['API_KEY'] = api_key
        os.environ['OPENAI_API_KEY'] = api_key
        os.environ['OPENAI_OR_Gemini_API_KEY'] = api_key
        
        # Set provider-specific keys
        if 'claude' in model.lower():
            os.environ['ANTHROPIC_API_KEY'] = api_key
        elif 'gemini' in model.lower():
            os.environ['GOOGLE_API_KEY'] = api_key
            os.environ['GEMINI_API_KEY'] = api_key
        
        # Initialize translation state in global storage
        user_id = interaction.user.id
        translation_states[user_id] = {
            'logs': [],
            'show_full': False,
            'stop_requested': False,
            'last_update': 0,
            'pending_update': False
        }
        state = translation_states[user_id]
        
        def log_callback(msg):
            if msg and msg.strip():
                state['logs'].append(msg.strip())
                # Use stderr to avoid recursion (stdout is redirected to callback)
                sys.stderr.write(f"[LOG] {msg.strip()}\n")
                sys.stderr.flush()
                
                # Rate limit: update at most once per second to avoid Discord rate limits
                import time
                current_time = time.time()
                if current_time - state['last_update'] >= 1.0:
                    state['last_update'] = current_time
                    state['pending_update'] = False
                    asyncio.run_coroutine_threadsafe(update_progress(), bot.loop)
                else:
                    # Mark that we have a pending update
                    state['pending_update'] = True
        
        def stop_callback():
            """Check if stop was requested"""
            return state['stop_requested']
        
        async def periodic_update_check():
            """Check for pending updates every second and flush them"""
            import time
            while user_id in translation_states and not state['stop_requested']:
                await asyncio.sleep(1)
                if state.get('pending_update', False):
                    state['pending_update'] = False
                    state['last_update'] = time.time()
                    await update_progress()
        
        async def update_progress():
            try:
                logs = state['logs']
                # Respect the user's choice of log view (show_full)
                if state['show_full']:
                    # Show all logs, truncated to Discord's 4096 char limit
                    log_text = '\n'.join(logs)
                    if len(log_text) > 3900:
                        log_text = "..." + log_text[-3900:]
                else:
                    # Show last 10 logs (increased from 5 for better visibility)
                    log_text = '\n'.join(logs[-10:])
                    if len(log_text) > 800:
                        log_text = log_text[-800:]
                
                if not log_text:
                    log_text = "Starting..."
                
                embed = discord.Embed(
                    title="ðŸ“š Translation in Progress",
                    description=f"**Status:** Processing... ({len(logs)} logs)\n\n```{log_text}```",
                    color=discord.Color.blue()
                )
                
                # Add buttons to toggle log view and stop translation
                view = LogView(user_id)
                await message.edit(embed=embed, view=view)
            except Exception as e:
                sys.stderr.write(f"[ERROR] Failed to update progress: {e}\n")
                sys.stderr.flush()
        
        # Run translation
        await update_progress()
        
        # Start periodic update checker
        update_task = asyncio.create_task(periodic_update_check())
        
        def run_translation():
            sys.stderr.write(f"[TRANSLATE] Starting translation for: {input_path}\n")
            sys.stderr.write(f"[TRANSLATE] Temp directory: {temp_dir}\n")
            sys.stderr.flush()
            
            # CRITICAL: Change to temp directory so TransateKRtoEN creates output there
            original_cwd = os.getcwd()
            try:
                os.chdir(temp_dir)
                sys.stderr.write(f"[TRANSLATE] Changed working directory to: {os.getcwd()}\n")
                sys.stderr.flush()
                
                sys.argv = ['discord_bot.py', input_path]
                result = TransateKRtoEN.main(log_callback=log_callback, stop_callback=stop_callback)
                
                sys.stderr.write(f"[TRANSLATE] Translation completed\n")
                sys.stderr.flush()
                return result
            finally:
                # Restore original working directory
                os.chdir(original_cwd)
                sys.stderr.write(f"[TRANSLATE] Restored working directory to: {os.getcwd()}\n")
                sys.stderr.flush()
        
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, run_translation)
        
        # Cancel the periodic update task
        update_task.cancel()
        try:
            await update_task
        except asyncio.CancelledError:
            pass
        
        # Determine output format and file
        output_file_path = None
        output_display_name = None
        is_zip_output = False

        # Prepare for potential zipping or searching
        output_base = os.path.splitext(filename)[0]  # Use filename variable, not file.filename
        safe_base = output_base.replace('/', '_').replace('\\', '_').replace(':', '_').replace('*', '_').replace('?', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_')
        output_subdir = os.path.join(temp_dir, safe_base)

        # If user didn't request zip, try to find the direct file first
        if not send_zip:
            sys.stderr.write(f"[OUTPUT] Searching for output file (ignoring zip)...\\n")
            # We look for .epub first as requested, then the input extension
            search_exts = ['.epub']
            input_ext = os.path.splitext(filename)[1].lower()
            if input_ext not in search_exts:
                search_exts.append(input_ext)
            
            search_dirs = []
            if os.path.exists(output_subdir) and os.path.isdir(output_subdir):
                search_dirs.append(output_subdir)
            search_dirs.append(temp_dir)
            
            for ext in search_exts:
                for d in search_dirs:
                    if not os.path.exists(d): continue
                    for f in os.listdir(d):
                        if f.endswith(ext):
                            f_path = os.path.join(d, f)
                            # Skip input file
                            if f_path != input_path:
                                output_file_path = f_path
                                output_display_name = f
                                sys.stderr.write(f"[OUTPUT] Found direct file: {output_file_path}\\n")
                                break
                    if output_file_path: break
                if output_file_path: break

        # If zip requested OR file not found, proceed with zipping
        if send_zip or not output_file_path:
            is_zip_output = True
            
            sys.stderr.write(f"[ZIP] Creating zip archive of output...\\n")
            sys.stderr.write(f"[ZIP] Temp dir: {temp_dir}\\n")
            sys.stderr.write(f"[ZIP] Expected output subdir: {output_subdir}\\n")
            
            # If output subdir exists, zip from there, otherwise zip from temp_dir root
            if os.path.exists(output_subdir) and os.path.isdir(output_subdir):
                zip_source_dir = output_subdir
                sys.stderr.write(f"[ZIP] Using output subdirectory as source\\n")
            else:
                zip_source_dir = temp_dir
                sys.stderr.write(f"[ZIP] Using temp dir as source (no subdirectory found)\\n")
            sys.stderr.flush()
            
            zip_filename = f"{safe_base}_translated.zip"
            zip_path = os.path.join(temp_dir, zip_filename)
            
            # Update status to show zipping
            embed = discord.Embed(
                title="ðŸ“¦ Creating Archive",
                description="Compressing output files...",
                color=discord.Color.blue()
            )
            try:
                await message.edit(embed=embed, view=None)
            except discord.errors.HTTPException:
                pass
            
            try:
                # Create zip archive in background thread
                def create_zip():
                    sys.stderr.write(f"[ZIP] Starting compression...\\n")
                    # ... (zip logic) ...
                    import zipfile
                    files_added = 0
                    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                        for root, dirs, files in os.walk(zip_source_dir):
                            for file_item in files:
                                file_path = os.path.join(root, file_item)
                                # Skip zip and input
                                if file_item.endswith('.zip'): continue
                                if file_path == input_path: continue
                                
                                arcname = os.path.relpath(file_path, zip_source_dir)
                                zipf.write(file_path, arcname)
                                files_added += 1
                    return zip_path
                
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, create_zip)
                
                output_file_path = zip_path
                output_display_name = zip_filename
                
            except Exception as e:
                sys.stderr.write(f"[ERROR] Failed to create zip: {e}\\n")
                raise e

        # Send the result (either zip or direct file)
        if os.path.exists(output_file_path):
            file_size = os.path.getsize(output_file_path)
            max_size = 25 * 1024 * 1024  # 25MB Discord limit
            
            sys.stderr.write(f"[SUCCESS] Ready to send: {output_file_path} ({file_size / 1024 / 1024:.2f}MB)\\n")
            
            if file_size > max_size:
                title = "â¹ï¸ Translation Stopped - File Too Large" if state['stop_requested'] else "âš ï¸ File Too Large"
                description = f"Output file ({file_size / 1024 / 1024:.2f}MB) exceeds Discord's 25MB limit"
                embed = discord.Embed(
                    title=title,
                    description=description,
                    color=discord.Color.orange()
                )
                try:
                    await message.edit(embed=embed, view=None)
                except discord.errors.HTTPException:
                    await interaction.followup.send(embed=embed)
            else:
                if state['stop_requested']:
                    title = "â¹ï¸ Translation Stopped - Partial Results"
                    desc_text = "Contains partial translation output."
                    color = discord.Color.orange()
                else:
                    title = "âœ… Translation Complete!"
                    desc_text = "Translation finished successfully."
                    color = discord.Color.green()
                
                embed = discord.Embed(
                    title=title,
                    description=f"**File:** {output_display_name}\\n**Size:** {file_size / 1024 / 1024:.2f}MB\\n\\n{desc_text}",
                    color=color
                )
                try:
                    await message.edit(embed=embed, view=None)
                except discord.errors.HTTPException:
                    await interaction.followup.send(embed=embed)
                
                try:
                    msg_content = f"Here's your {('zipped ' if is_zip_output else '')}translation output!"
                    await interaction.followup.send(
                        msg_content,
                        file=discord.File(output_file_path, filename=output_display_name),
                        ephemeral=_ephemeral(interaction)
                    )
                except discord.errors.HTTPException as e:
                    await interaction.followup.send(
                        f"Translation complete but file is too large to upload ({file_size / 1024 / 1024:.2f}MB).\n"
                        f"Please retrieve it from the server.",
                        ephemeral=_ephemeral(interaction)
                    )
        else:
            raise FileNotFoundError(f"Output file not found: {output_file_path}")
    
    except Exception as e:
        import traceback
        error = f"```\n{traceback.format_exc()[-1000:]}\n```"
        embed = discord.Embed(
            title="âŒ Error",
            description=f"{str(e)}\n{error}",
            color=discord.Color.red()
        )
        try:
            await message.edit(embed=embed, view=None)
        except discord.errors.HTTPException:
            await interaction.followup.send(embed=embed)
    
    finally:
        # Cleanup translation state
        if user_id in translation_states:
            del translation_states[user_id]
        
        # Cleanup temp directory
        try:
            shutil.rmtree(temp_dir)
        except:
            pass


@bot.tree.command(name="extract", description="Extract glossary from EPUB, TXT, or PDF file")
@app_commands.describe(
    api_key="Your API key",
    model="AI model to use (or type custom model name)",
    file="EPUB, TXT, or PDF file to extract glossary from (optional if using url)",
    url="Google Drive or Dropbox link to file (optional if using file attachment)",
    custom_endpoint_url="Custom OpenAI-compatible base URL (auto-enables when set; omit to disable)",
    google_credentials_path="Path to Google Cloud credentials JSON (for Vertex AI models)",
    extraction_mode="Text extraction method (default: Enhanced/html2text)",
    temperature="Glossary extraction temperature 0.0-1.0 (default: 0.1)",
    batch_size="Paragraphs per batch (default: 10)",
    max_output_tokens="Max output tokens (default: 65536)",
    glossary_compression_factor="Glossary compression factor (default: 1.0)",
    merge_count="Chapters per request (set >=2 to enable request merging; <=1 disables; omit to disable)",
    duplicate_algorithm="Duplicate handling: auto/strict/balanced/aggressive/basic (default: balanced)",
    send_zip="Return output as a ZIP archive instead of individual file (default: False)",
    thinking="Enable/disable AI thinking capabilities (GPT/Gemini/DeepSeek) - Default: True",
    gemini_thinking_level="Gemini 3 thinking level (low/high) - Default: high",
    gemini_thinking_budget="Gemini thinking budget (-1=auto, 0=disabled) - Default: -1",
    or_thinking_tokens="OpenRouter thinking tokens - Default: 2000",
    gpt_effort="GPT-5/OpenAI thinking effort (none/low/medium/high/xhigh) - Default: medium",
    target_language="Target language for translations"
)
@app_commands.choices(extraction_mode=[
    app_commands.Choice(name="Enhanced (html2text)", value="enhanced"),
    app_commands.Choice(name="Standard (BeautifulSoup)", value="standard"),
])
@app_commands.choices(gemini_thinking_level=[
    app_commands.Choice(name="High", value="high"),
    app_commands.Choice(name="Low", value="low"),
])
@app_commands.choices(gpt_effort=[
    app_commands.Choice(name="None", value="none"),
    app_commands.Choice(name="Low", value="low"),
    app_commands.Choice(name="Medium", value="medium"),
    app_commands.Choice(name="High", value="high"),
    app_commands.Choice(name="XHigh", value="xhigh"),
])
@app_commands.autocomplete(model=model_autocomplete)
async def extract(
    interaction: discord.Interaction,
    api_key: str,
    model: str,
    file: discord.Attachment = None,
    url: str = None,
    custom_endpoint_url: Optional[str] = None,
    google_credentials_path: str = None,
    extraction_mode: str = "enhanced",
    temperature: float = 0.1,
    batch_size: int = 10,
    max_output_tokens: int = 65536,
    glossary_compression_factor: float = 1.0,
    merge_count: Optional[int] = None,
    duplicate_algorithm: str = "balanced",
    send_zip: bool = False,
    thinking: bool = True,
    gemini_thinking_level: str = "high",
    gemini_thinking_budget: int = -1,
    or_thinking_tokens: int = 2000,
    gpt_effort: str = "medium",
    target_language: str = "English"
):
    """Extract glossary from file using Glossarion"""
    
    if not GLOSSARION_AVAILABLE or not glossary_main:
        await interaction.response.send_message(
            "âŒ Glossarion glossary extraction not available", 
            ephemeral=_ephemeral(interaction)
        )
        return
    
    # Validate input - must have either file or URL
    if not file and not url:
        await interaction.response.send_message(
            "âŒ Please provide either a file attachment or a URL", 
            ephemeral=_ephemeral(interaction)
        )
        return
    
    # Get filename and validate extension
    if file:
        filename = file.filename
    elif url:
        # Extract filename from URL or use default
        if 'drive.google.com' in url:
            filename = 'google_drive_file.epub'
        elif 'dropbox.com' in url:
            filename = 'dropbox_file.epub'
        else:
            from urllib.parse import urlparse, unquote
            parsed = urlparse(url)
            filename = unquote(os.path.basename(parsed.path)) or 'downloaded_file.epub'

    # Never trust user/remote-provided names to be a safe path.
    # Keep /extract isolated from path traversal and accidental subdirectories.
    filename = os.path.basename(filename)

    # Validate file extension
    if not (filename.endswith('.epub') or filename.endswith('.txt') or filename.endswith('.pdf')):
        await interaction.response.send_message(
            "âŒ File must be EPUB, TXT, or PDF format", 
            ephemeral=_ephemeral(interaction)
        )
        return

    # Validate request merge count early (if explicitly provided)
    if merge_count is not None and merge_count < 0:
        await interaction.response.send_message(
            "âŒ merge_count must be >= 0",
            ephemeral=_ephemeral(interaction)
        )
        return

    # Validate custom endpoint URL early (if provided)
    if custom_endpoint_url is not None:
        custom_endpoint_url = custom_endpoint_url.strip()
        if custom_endpoint_url and not (custom_endpoint_url.startswith('http://') or custom_endpoint_url.startswith('https://')):
            await interaction.response.send_message(
                "âŒ custom_endpoint_url must start with http:// or https://",
                ephemeral=_ephemeral(interaction)
            )
            return
    
    # Initial response
    embed = discord.Embed(
        title="ðŸ“š Glossary Extraction Started",
        description=f"**File:** {filename}\n**Model:** {model}\n**Target:** {target_language}",
        color=discord.Color.blue()
    )
    await interaction.response.send_message(embed=embed, ephemeral=_ephemeral(interaction))
    message = await interaction.original_response()
    
    # Create temp directory
    temp_dir = tempfile.mkdtemp(prefix=f"discord_extract_{interaction.user.id}_")
    input_path = os.path.join(temp_dir, filename)
    
    try:
        # Download file from attachment or URL
        if file:
            await file.save(input_path)
        elif url:
            import aiohttp
            
            # Convert Google Drive/Dropbox share links to direct download links
            download_url = url
            if 'drive.google.com' in url:
                if '/file/d/' in url:
                    file_id = url.split('/file/d/')[1].split('/')[0]
                elif 'id=' in url:
                    file_id = url.split('id=')[1].split('&')[0]
                else:
                    await interaction.edit_original_response(embed=discord.Embed(
                        title="âŒ Invalid URL",
                        description="Could not parse Google Drive file ID from URL",
                        color=discord.Color.red()
                    ))
                    return
                download_url = f"https://drive.google.com/uc?export=download&id={file_id}"
            elif 'dropbox.com' in url:
                download_url = url.replace('www.dropbox.com', 'dl.dropboxusercontent.com').replace('?dl=0', '').replace('?dl=1', '')
                if '?dl=' not in download_url:
                    download_url += '?dl=1'
            
            # Download the file
            async with aiohttp.ClientSession() as session:
                async with session.get(download_url) as response:
                    if response.status == 200:
                        with open(input_path, 'wb') as f:
                            f.write(await response.read())
                        
                        # Try to get actual filename from response headers
                        if 'content-disposition' in response.headers:
                            import re
                            content_disp = response.headers['content-disposition']
                            fname_match = re.findall('filename="(.+)"', content_disp)
                            if fname_match:
                                actual_filename = os.path.basename(fname_match[0])
                                new_input_path = os.path.join(temp_dir, actual_filename)
                                os.rename(input_path, new_input_path)
                                input_path = new_input_path
                                filename = actual_filename
                    else:
                        await interaction.edit_original_response(embed=discord.Embed(
                            title="âŒ Download Failed",
                            description=f"Failed to download file from URL (HTTP {response.status})",
                            color=discord.Color.red()
                        ))
                        return

        # Ensure the input file actually exists before starting the executor thread.
        try:
            if not os.path.isfile(input_path):
                raise FileNotFoundError(f"Downloaded/attached file not found on disk: {input_path}")
            if os.path.getsize(input_path) <= 0:
                raise FileNotFoundError(f"Downloaded/attached file is empty: {input_path}")
        except Exception as e:
            await interaction.edit_original_response(embed=discord.Embed(
                title="âŒ Input File Error",
                description=str(e),
                color=discord.Color.red()
            ))
            return

        # Load config
        config = load_config()
        
        # Get glossary prompts from config
        glossary_prompt = config.get('manual_glossary_prompt', '')
        
        # Custom OpenAI Endpoint (single source of truth: custom_endpoint_url)
        # If omitted, keep disabled.
        if custom_endpoint_url:
            os.environ['USE_CUSTOM_OPENAI_ENDPOINT'] = '1'
            os.environ['OPENAI_CUSTOM_BASE_URL'] = custom_endpoint_url
            sys.stderr.write(f"[CONFIG] Custom OpenAI Endpoint enabled: {custom_endpoint_url}\n")
        else:
            os.environ['USE_CUSTOM_OPENAI_ENDPOINT'] = '0'
            os.environ['OPENAI_CUSTOM_BASE_URL'] = ''
        
        # Set model and API key
        os.environ['MODEL'] = model
        os.environ['GLOSSARY_SYSTEM_PROMPT'] = glossary_prompt
        
        # Set translation parameters (same as /translate)
        os.environ['BATCH_TRANSLATION'] = '1'
        os.environ['BATCH_SIZE'] = str(batch_size)
        os.environ['MAX_OUTPUT_TOKENS'] = str(max_output_tokens)
        os.environ['GLOSSARY_TEMPERATURE'] = str(temperature)
        os.environ['TRANSLATION_TEMPERATURE'] = str(temperature)
        os.environ['GLOSSARY_MAX_OUTPUT_TOKENS'] = str(max_output_tokens)
        
        # Set extraction mode
        os.environ['TEXT_EXTRACTION_METHOD'] = extraction_mode
        if extraction_mode == 'enhanced':
            os.environ['EXTRACTION_MODE'] = 'enhanced'
            os.environ['ENHANCED_FILTERING'] = 'smart'
            os.environ['ENHANCED_PRESERVE_STRUCTURE'] = '1'
        else:
            os.environ['EXTRACTION_MODE'] = 'smart'
            os.environ['FILE_FILTERING_LEVEL'] = 'smart'
        
        # Set PDF-specific styling extraction variables from pdf_extractor
        # These ensure PDF font sizes, alignments, and styles are preserved
        if filename.endswith('.pdf'):
            sys.stderr.write(f"[CONFIG] Enabling PDF formatting extraction (font size, alignment, etc.)\n")
            sys.stderr.flush()
            # Force XHTML render mode for better PDF extraction quality
            os.environ['PDF_RENDER_MODE'] = 'xhtml'
            sys.stderr.write(f"[CONFIG] Using XHTML render mode for PDF\n")
            sys.stderr.flush()
            # The pdf_extractor.generate_css_from_pdf() function will automatically
            # detect and apply: base_font_size, font_family, text_align, line_height_ratio
            # from the actual PDF file during processing
        
        # Set all glossary variables from config (same as /translate)
        os.environ['ENABLE_AUTO_GLOSSARY'] = '1'
        os.environ['GLOSSARY_MIN_FREQUENCY'] = str(config.get('glossary_min_frequency', 2))
        os.environ['GLOSSARY_MAX_NAMES'] = str(config.get('glossary_max_names', 50))
        os.environ['GLOSSARY_MAX_TITLES'] = str(config.get('glossary_max_titles', 30))
        os.environ['GLOSSARY_COMPRESSION_FACTOR'] = str(glossary_compression_factor)
        os.environ['GLOSSARY_FILTER_MODE'] = config.get('glossary_filter_mode', 'all')
        os.environ['GLOSSARY_STRIP_HONORIFICS'] = '1' if config.get('glossary_strip_honorifics', True) else '0'
        os.environ['GLOSSARY_FUZZY_THRESHOLD'] = str(config.get('glossary_fuzzy_threshold', 0.90))
        os.environ['GLOSSARY_MAX_TEXT_SIZE'] = str(config.get('glossary_max_text_size', 50000))
        # Cap glossary max sentences for the Discord bot to keep prompts small/predictable.
        # (GlossaryManager reads this via GLOSSARY_MAX_SENTENCES)
        os.environ['GLOSSARY_MAX_SENTENCES'] = '200'
        os.environ['GLOSSARY_CHAPTER_SPLIT_THRESHOLD'] = str(config.get('glossary_chapter_split_threshold', 50000))
        os.environ['GLOSSARY_SKIP_FREQUENCY_CHECK'] = '0'
        os.environ['CONTEXT_WINDOW_SIZE'] = str(config.get('glossary_context_window', 2))
        os.environ['GLOSSARY_CONTEXT_LIMIT'] = str(config.get('manual_context_limit', 2))
        os.environ['GLOSSARY_USE_LEGACY_CSV'] = '0'
        os.environ['GLOSSARY_DUPLICATE_KEY_MODE'] = 'skip'
        os.environ['GLOSSARY_DISABLE_HONORIFICS_FILTER'] = '1' if config.get('glossary_disable_honorifics_filter', False) else '0'
        # Ensure glossary output language matches the command's target_language
        os.environ['GLOSSARY_TARGET_LANGUAGE'] = target_language
        os.environ['OUTPUT_LANGUAGE'] = target_language
        # Align throttling/timeouts with config defaults (matches GUI behavior)
        os.environ['SEND_INTERVAL_SECONDS'] = str(config.get('delay', 2.0))
        os.environ['THREAD_SUBMISSION_DELAY_SECONDS'] = str(config.get('thread_submission_delay', 0.5))
        os.environ['RETRY_TIMEOUT'] = '1' if config.get('retry_timeout', False) else '0'
        os.environ['CHUNK_TIMEOUT'] = str(config.get('chunk_timeout', 900))
        os.environ['ENABLE_HTTP_TUNING'] = '1' if config.get('enable_http_tuning', False) else '0'
        os.environ['CONNECT_TIMEOUT'] = str(config.get('connect_timeout', 10))
        # Don't set READ_TIMEOUT for the bot; chunk timeout is the single source of truth.
        os.environ.pop('READ_TIMEOUT', None)
        os.environ['HTTP_POOL_CONNECTIONS'] = str(config.get('http_pool_connections', 20))
        os.environ['HTTP_POOL_MAXSIZE'] = str(config.get('http_pool_maxsize', 50))
        os.environ['IGNORE_RETRY_AFTER'] = '1' if config.get('ignore_retry_after', False) else '0'
        # Cap retries for the Discord bot to keep runs predictable.
        os.environ['MAX_RETRIES'] = '3'

        # Glossary request merging settings
        # Single source of truth: merge_count
        if merge_count is None:
            # If omitted, keep merging disabled
            glossary_request_merging_enabled = False
            glossary_request_merge_count_raw = 1
        else:
            glossary_request_merge_count_raw = int(merge_count)
            glossary_request_merging_enabled = glossary_request_merge_count_raw >= 2

        # Keep the count safe for downstream code (even when disabled)
        glossary_request_merge_count_effective = max(1, glossary_request_merge_count_raw)

        os.environ['GLOSSARY_REQUEST_MERGING_ENABLED'] = '1' if glossary_request_merging_enabled else '0'
        os.environ['GLOSSARY_REQUEST_MERGE_COUNT'] = str(glossary_request_merge_count_effective)
        os.environ['GLOSSARY_DUPLICATE_ALGORITHM'] = duplicate_algorithm
        # Use config defaults for gender context and description (manual glossary extraction)
        os.environ['GLOSSARY_INCLUDE_GENDER_CONTEXT'] = '1' if config.get('include_gender_context', True) else '0'
        os.environ['GLOSSARY_INCLUDE_DESCRIPTION'] = '1' if config.get('include_description', True) else '0'
        # Custom glossary fields (additional columns) - default to ['description']
        custom_fields = config.get('custom_glossary_fields', [])
        if not custom_fields and not config.get('custom_field_description_removed', False):
            custom_fields = ['description']
        os.environ['GLOSSARY_CUSTOM_FIELDS'] = json.dumps(custom_fields)
        os.environ['DISABLE_GEMINI_SAFETY'] = 'true'
        
        # Handle Thinking Toggle
        if not thinking:
            os.environ['ENABLE_GPT_THINKING'] = '0'
            os.environ['ENABLE_GEMINI_THINKING'] = '0'
            os.environ['ENABLE_DEEPSEEK_THINKING'] = '0'
            sys.stderr.write(f"[CONFIG] Thinking capabilities disabled via command\n")
        else:
            # Set specific thinking variables if thinking is enabled
            os.environ['GEMINI_THINKING_LEVEL'] = gemini_thinking_level
            os.environ['THINKING_BUDGET'] = str(gemini_thinking_budget)
            os.environ['GPT_REASONING_TOKENS'] = str(or_thinking_tokens)
            os.environ['GPT_EFFORT'] = gpt_effort
        
        # Handle Vertex AI / Google Cloud credentials
        if '@' in model or model.startswith('vertex/'):
            # Use provided credentials path, fallback to config if not provided
            google_creds = google_credentials_path if google_credentials_path else config.get('google_cloud_credentials')
            if google_creds and os.path.exists(google_creds):
                os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = google_creds
                sys.stderr.write(f"[CONFIG] Using Google Cloud credentials: {os.path.basename(google_creds)}\n")
                sys.stderr.flush()
                
                try:
                    with open(google_creds, 'r') as f:
                        creds_data = json.load(f)
                        project_id = creds_data.get('project_id', 'vertex-ai-project')
                        os.environ['GOOGLE_CLOUD_PROJECT'] = project_id
                        if not api_key:
                            api_key = project_id
                except:
                    pass
        
        # Set API key
        os.environ['API_KEY'] = api_key
        os.environ['OPENAI_API_KEY'] = api_key
        os.environ['OPENAI_OR_Gemini_API_KEY'] = api_key
        
        if 'claude' in model.lower():
            os.environ['ANTHROPIC_API_KEY'] = api_key
        elif 'gemini' in model.lower():
            os.environ['GOOGLE_API_KEY'] = api_key
            os.environ['GEMINI_API_KEY'] = api_key
        
        # Initialize extraction state
        user_id = interaction.user.id
        translation_states[user_id] = {
            'logs': [],
            'show_full': False,
            'stop_requested': False,
            'last_update': 0,
            'pending_update': False
        }
        state = translation_states[user_id]
        
        def log_callback(msg):
            if msg and msg.strip():
                state['logs'].append(msg.strip())
                sys.stderr.write(f"[LOG] {msg.strip()}\n")
                sys.stderr.flush()
                
                import time
                current_time = time.time()
                if current_time - state['last_update'] >= 1.0:
                    state['last_update'] = current_time
                    state['pending_update'] = False
                    asyncio.run_coroutine_threadsafe(update_progress(), bot.loop)
                else:
                    state['pending_update'] = True
        
        def stop_callback():
            return state['stop_requested']
        
        async def periodic_update_check():
            import time
            while user_id in translation_states and not state['stop_requested']:
                await asyncio.sleep(1)
                if state.get('pending_update', False):
                    state['pending_update'] = False
                    state['last_update'] = time.time()
                    await update_progress()
        
        async def update_progress():
            try:
                logs = state['logs']
                if state['show_full']:
                    log_text = '\n'.join(logs)
                    if len(log_text) > 3900:
                        log_text = "..." + log_text[-3900:]
                else:
                    log_text = '\n'.join(logs[-10:])
                    if len(log_text) > 800:
                        log_text = log_text[-800:]
                
                if not log_text:
                    log_text = "Starting..."
                
                embed = discord.Embed(
                    title="ðŸ“š Glossary Extraction in Progress",
                    description=f"**Status:** Processing... ({len(logs)} logs)\n\n```{log_text}```",
                    color=discord.Color.blue()
                )
                
                view = LogView(user_id)
                await message.edit(embed=embed, view=view)
            except Exception as e:
                sys.stderr.write(f"[ERROR] Failed to update progress: {e}\n")
                sys.stderr.flush()
        
        await update_progress()
        update_task = asyncio.create_task(periodic_update_check())
        
        def run_extraction():
            sys.stderr.write(f"[EXTRACT] Starting glossary extraction for: {input_path}\n")
            sys.stderr.write(f"[EXTRACT] Temp directory: {temp_dir}\n")
            sys.stderr.flush()

            # Defensive checks: if these fail, raise an explicit error instead of a generic Errno 2.
            if not os.path.isdir(temp_dir):
                raise FileNotFoundError(f"Temp directory does not exist: {temp_dir}")
            if not os.path.isfile(input_path):
                raise FileNotFoundError(f"Input file does not exist: {input_path}")

            # Avoid chdir() to eliminate CWD-dependent bugs and races.
            # Use absolute output/config paths so the extractor is deterministic.
            output_base = os.path.splitext(os.path.basename(filename))[0] or "glossary"
            output_path = os.path.join(temp_dir, f"{output_base}_glossary.json")

            # Bot-only deployments often don't ship a config.json (it's gitignored).
            # The extractor currently expects a file path, so if one isn't present,
            # create a minimal config in the temp dir and rely on env vars (API_KEY, MODEL, etc.).
            config_path = CONFIG_FILE
            if not os.path.exists(config_path):
                config_path = os.path.join(temp_dir, "config.json")
                try:
                    if not os.path.exists(config_path):
                        with open(config_path, "w", encoding="utf-8") as f:
                            json.dump({}, f)
                except Exception as e:
                    # If we can't write a temp config for any reason, fall back to the original path
                    # so the error message is explicit.
                    sys.stderr.write(f"[EXTRACT] Failed to create temp config.json: {e}\n")
                    sys.stderr.flush()
                    config_path = CONFIG_FILE

            original_argv = sys.argv[:]
            try:
                sys.argv = [
                    'extract_glossary_from_epub.py',
                    '--epub', input_path,
                    '--output', output_path,
                    '--config', config_path
                ]

                glossary_main(log_callback=log_callback, stop_callback=stop_callback)

                sys.stderr.write(f"[EXTRACT] Glossary extraction completed\n")
                sys.stderr.flush()
                return output_path
            finally:
                # Prevent leaking argv changes across commands.
                sys.argv = original_argv
        
        loop = asyncio.get_event_loop()
        extraction_future = loop.run_in_executor(None, run_extraction)
        output_filename = await extraction_future

        update_task.cancel()
        try:
            await update_task
        except asyncio.CancelledError:
            pass
        
        if state['stop_requested']:
            embed = discord.Embed(
                title="â¹ï¸ Extraction Stopped",
                description="Glossary extraction was stopped by user.",
                color=discord.Color.orange()
            )
            await message.edit(embed=embed, view=None)
            return
        
        # Find the Glossary output directory
        glossary_dir = os.path.join(temp_dir, 'Glossary')
        
        output_file_path = None
        output_display_name = None
        is_zip_output = False
        
        if os.path.exists(glossary_dir) and os.path.isdir(glossary_dir):
            
            if not send_zip:
                # Search for .csv in glossary_dir
                for f in os.listdir(glossary_dir):
                    if f.endswith('.csv'):
                        output_file_path = os.path.join(glossary_dir, f)
                        output_display_name = f
                        break
            
            # Fallback to ZIP
            if send_zip or not output_file_path:
                is_zip_output = True
                
                # Create zip of entire Glossary folder
                output_base = os.path.splitext(filename)[0]
                zip_filename = f"{output_base}_glossary.zip"
                zip_path = os.path.join(temp_dir, zip_filename)
                
                import zipfile
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for root, dirs, files in os.walk(glossary_dir):
                        for file_item in files:
                            file_path = os.path.join(root, file_item)
                            arcname = os.path.relpath(file_path, glossary_dir)
                            zipf.write(file_path, arcname)
                
                output_file_path = zip_path
                output_display_name = zip_filename

            # Send output
            if output_file_path and os.path.exists(output_file_path):
                file_size = os.path.getsize(output_file_path)
                
                embed = discord.Embed(
                    title="âœ… Glossary Extraction Complete!",
                    description=f"**File:** {output_display_name}\\n**Size:** {file_size / 1024:.2f}KB",
                    color=discord.Color.green()
                )
                await message.edit(embed=embed, view=None)
                
                try:
                    await interaction.followup.send(
                        f"Here's your extracted glossary{(' (zipped)' if is_zip_output else '')}!",
                        file=discord.File(output_file_path, filename=output_display_name),
                        ephemeral=_ephemeral(interaction)
                    )
                except discord.errors.HTTPException as e:
                    await interaction.followup.send(
                        f"Glossary complete but file is too large to upload.\n"
                        f"Please retrieve it from the server.",
                        ephemeral=_ephemeral(interaction)
                    )
            else:
                 # Should not happen if directory exists
                embed = discord.Embed(
                    title="âŒ Extraction Failed",
                    description="Could not prepare output file",
                    color=discord.Color.red()
                )
                await message.edit(embed=embed, view=None)
                
        else:
            embed = discord.Embed(
                title="âŒ Extraction Failed",
                description="Could not find Glossary output directory",
                color=discord.Color.red()
            )
            await message.edit(embed=embed, view=None)
    
    except Exception as e:
        import traceback
        error = f"```\n{traceback.format_exc()[-1000:]}\n```"
        embed = discord.Embed(
            title="âŒ Error",
            description=f"{str(e)}\n{error}",
            color=discord.Color.red()
        )
        await message.edit(embed=embed, view=None)
    
    finally:
        # Ensure the background extraction thread has finished before removing temp_dir.
        # If we delete early, the executor thread can crash with FileNotFoundError.
        try:
            if 'state' in locals():
                state['stop_requested'] = True
        except Exception:
            pass

        try:
            if 'update_task' in locals() and update_task:
                update_task.cancel()
        except Exception:
            pass

        try:
            if 'extraction_future' in locals() and extraction_future and not extraction_future.done():
                try:
                    await asyncio.wait_for(extraction_future, timeout=10)
                except Exception:
                    # If it doesn't finish quickly, don't delete the directory out from under it.
                    pass
        except Exception:
            pass

        if user_id in translation_states:
            del translation_states[user_id]

        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
        except Exception:
            pass


@bot.tree.command(name="models", description="List available AI models")
async def models(interaction: discord.Interaction):
    """List available models"""
    if GLOSSARION_AVAILABLE:
        model_list = get_model_options()
        
        # Group by provider
        providers = {}
        for model in model_list:
            provider = model.split('-')[0] if '-' in model else model
            if provider not in providers:
                providers[provider] = []
            providers[provider].append(model)
        
        embed = discord.Embed(
            title="ðŸ¤– Available Models",
            description="Use with `/translate`",
            color=discord.Color.blue()
        )
        
        for provider, mods in list(providers.items())[:10]:
            text = '\n'.join([f"â€¢ `{m}`" for m in mods[:5]])
            if len(mods) > 5:
                text += f"\nâ€¢ ... +{len(mods) - 5} more"
            embed.add_field(name=provider.upper(), value=text, inline=True)
        
        await interaction.response.send_message(embed=embed, ephemeral=_ephemeral(interaction))
    else:
        await interaction.response.send_message("âŒ Not available", ephemeral=_ephemeral(interaction))


@bot.tree.command(name="help", description="Show help")
async def help_command(interaction: discord.Interaction):
    """Show help"""
    embed = discord.Embed(
        title="ðŸ“š Glossarion Discord Bot",
        description="Translate EPUB/TXT files using AI",
        color=discord.Color.blue()
    )
    
    embed.add_field(
        name="Commands",
        value="`/translate` - Translate file\\n`/extract` - Extract glossary\\n`/models` - List models\\n`/help` - This message\\n\\nUse `send_zip: True` to force ZIP output.",
        inline=False
    )
    
    embed.add_field(
        name="Example",
        value="```\n/translate\n  file: novel.epub\n  api_key: sk-...\n  model: gpt-4\n  target_language: English\n```",
        inline=False
    )
    
    embed.add_field(
        name="Notes",
        value="â€¢ Max file size: 25MB\nâ€¢ Uses your Glossarion config\nâ€¢ API key not stored",
        inline=False
    )
    
    await interaction.response.send_message(embed=embed, ephemeral=_ephemeral(interaction))


def main():
    """Start bot"""
    token = os.getenv('DISCORD_BOT_TOKEN')
    
    if not token:
        print("âŒ DISCORD_BOT_TOKEN not set!")
        print("\nSetup:")
        print("1. Create bot at https://discord.com/developers/applications")
        print("2. Get token from Bot section")
        print("3. Set environment variable:")
        print("   Windows: set DISCORD_BOT_TOKEN=your_token")
        print("   Linux/Mac: export DISCORD_BOT_TOKEN=your_token")
        print("4. Invite bot with 'bot' + 'applications.commands' scopes")
        return
    
    if not GLOSSARION_AVAILABLE:
        print("âš ï¸ Glossarion not available - translations will fail")
    
    print("ðŸš€ Starting Glossarion Discord Bot...")
    bot.run(token)


if __name__ == "__main__":
    main()
